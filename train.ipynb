{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data = pd.read_csv('/project/at081-group38/AT081193_ER/bert_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>date</th>\n",
       "      <th>news_guid</th>\n",
       "      <th>title</th>\n",
       "      <th>news_content</th>\n",
       "      <th>content_remove_html_tag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/news/1999-06-14/0b7a5d15-7bcd-11d3...</td>\n",
       "      <td>19990614074852</td>\n",
       "      <td>0B7A5D15-7BCD-11D3-98FF-00E018A00403</td>\n",
       "      <td>導線架市場重新洗牌新台和順德談策略聯盟                           ...</td>\n",
       "      <td>\\n\\n\\n&lt;P&gt;在大廠壓縮小廠生存空間，小廠試圖尋求同業策略聯盟的趨勢下，國內3大導線架廠...</td>\n",
       "      <td>在大廠壓縮小廠生存空間，小廠試圖尋求同業策略聯盟的趨勢下，國內3大導線架廠包括順德、佳茂、旭...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/news/2009-08-06/3b508922-e6a5-4c25...</td>\n",
       "      <td>20090806111315</td>\n",
       "      <td>3B508922-E6A5-4C25-B80F-01E8B36BB835</td>\n",
       "      <td>建築鋼每噸利潤達1000元 中國鐵礦石庫存逼新高                      ...</td>\n",
       "      <td>\\n&lt;P&gt;精實新聞 2009-08-06 11:13:15 記者 余美慧 報導&lt;/P&gt;&lt;P&gt;...</td>\n",
       "      <td>精實新聞 2009-08-06 11:13:15 記者 余美慧 報導聯合金屬網統計，截至7月...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../datasets/news/2009-08-06/b325cc3e-e7b8-417a...</td>\n",
       "      <td>20090806074535</td>\n",
       "      <td>B325CC3E-E7B8-417A-8177-8BEA7A367F00</td>\n",
       "      <td>昇貿利基產品比重提升、新客戶加入，H2樂觀                         ...</td>\n",
       "      <td>\\n&lt;P&gt;精實新聞 2009-08-06 07:45:35 記者 楊喻斐 報導&lt;/P&gt;&lt;P&gt;...</td>\n",
       "      <td>精實新聞 2009-08-06 07:45:35 記者 楊喻斐 報導銲錫製品大廠昇貿(330...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path            date  \\\n",
       "0  ../datasets/news/1999-06-14/0b7a5d15-7bcd-11d3...  19990614074852   \n",
       "1  ../datasets/news/2009-08-06/3b508922-e6a5-4c25...  20090806111315   \n",
       "2  ../datasets/news/2009-08-06/b325cc3e-e7b8-417a...  20090806074535   \n",
       "\n",
       "                              news_guid  \\\n",
       "0  0B7A5D15-7BCD-11D3-98FF-00E018A00403   \n",
       "1  3B508922-E6A5-4C25-B80F-01E8B36BB835   \n",
       "2  B325CC3E-E7B8-417A-8177-8BEA7A367F00   \n",
       "\n",
       "                                               title  \\\n",
       "0  導線架市場重新洗牌新台和順德談策略聯盟                           ...   \n",
       "1  建築鋼每噸利潤達1000元 中國鐵礦石庫存逼新高                      ...   \n",
       "2  昇貿利基產品比重提升、新客戶加入，H2樂觀                         ...   \n",
       "\n",
       "                                        news_content  \\\n",
       "0  \\n\\n\\n<P>在大廠壓縮小廠生存空間，小廠試圖尋求同業策略聯盟的趨勢下，國內3大導線架廠...   \n",
       "1  \\n<P>精實新聞 2009-08-06 11:13:15 記者 余美慧 報導</P><P>...   \n",
       "2  \\n<P>精實新聞 2009-08-06 07:45:35 記者 楊喻斐 報導</P><P>...   \n",
       "\n",
       "                             content_remove_html_tag  label  \n",
       "0  在大廠壓縮小廠生存空間，小廠試圖尋求同業策略聯盟的趨勢下，國內3大導線架廠包括順德、佳茂、旭...      0  \n",
       "1  精實新聞 2009-08-06 11:13:15 記者 余美慧 報導聯合金屬網統計，截至7月...      0  \n",
       "2  精實新聞 2009-08-06 07:45:35 記者 楊喻斐 報導銲錫製品大廠昇貿(330...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可放 content_remove_html_tag/title\n",
    "data=merge_data\n",
    "a=data[data.label==1]\n",
    "b=data[data.label==0]\n",
    "data=pd.concat([a,b],axis=0)\n",
    "\n",
    "data_for_bert = []\n",
    "strat_list = []\n",
    "for i in range(len(data)):\n",
    "    data_for_bert.append((i, #guid\n",
    "                          data.iloc[i,:]['title'].strip()+' '+data.iloc[i,:][\"content_remove_html_tag\"], #text_a\n",
    "                          None, #text_b\n",
    "                          data.iloc[i,:].label #label\n",
    "                         ))\n",
    "    strat_list.append(data.iloc[i,:].label)\n",
    "    \n",
    "train, dev = train_test_split(data_for_bert, test_size=0.2, stratify=strat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39012,\n",
       " '鄭貞茂：建構健全監理法制，引領金融科技創新發展 MoneyDJ新聞 2018-03-28 17:24:03 記者 新聞中心 報導2018富邦金控暨臺大財金系金融論壇今(28)日登場，由臺灣大學管理學院副院長陳業寧引言，臺灣大學財金系教授何耕宇主持，金管會副主委鄭貞茂、源鉑資本創辦人兼執行長胡一天、台北富邦銀行總經理程耀輝等三位專家針對「智能金融－場景化的金融服務」主題深入與談。鄭貞茂表示，為鼓勵金融創新，金管會積極建構有利於金融科技創新和發展的環境與產業共同前進，讓有益社會的創新金融商品或服務能萌芽發展，也讓業者有機會實現及測試好的創新構想，進而營造負責任創新環境，為金融消費者提供充足的保障。鄭貞茂指出，台灣在今年1月公布「金融科技發展與創新實驗條例」，成為全球第一個以成文法推動監理沙盒的國家，其中擬參考國外虛擬沙盒(Virtual Sandbox)作法，設置數位沙盒，規劃成立「金融科技創新園區」，作為監理沙盒的前置實驗場域。為有效執行相關政策，今年2月也成立了「金融科技發展與創新中心」，轄下並設立創新發展組及園區發展組。鄭貞茂強調，未來將因應金融科技創新需要，建構健全的監理法制，在兼顧金融市場秩序及消費者權益下，引領金融科技創新發展，營造一個負責任創新的環境，為金融產業創造價值，並增進社會大眾福祉，實現普惠金融目標。胡一天表示，金融科技與區塊鏈創新是互聯網大趨勢的新階段，對人類的生活與工作已產生不可磨滅的影響，而在這次智能金融驅動的新階段能成功轉型的金融機構，將會是能深刻理解各種商業場景的需求，善用資訊科技並與新創企業合作，提供更多、更好、更適合的金融服務。他並指出，源鉑資本自2015年創辦以來，專注金融創新領域的早期投資機會，目前已投資的十四個項目中，就有在支付、旅遊、醫療、群募、資訊安全與宏觀投資等領域深耕的新創企業；未來將持續透過其全球資源網絡，推動更豐富的創新生態系。程耀輝表示，「金融服務生活化」已成為不可擋的趨勢，北富銀積極運用金融科技技術，將金融服務融入消費者生活場景，包括可24小時線上諮詢的富邦數位客服；全年無休的富邦行動銀行；2017年更率先與台灣大Wali APP合作，創新推出結合信用卡、悠遊卡與自動加值的整合性行動支付服務，今年3月將成為首批與悠遊卡合作帳戶連結自動加值之銀行，為小額支付、通勤族帶來方便。富邦金董事長蔡明興表示，富邦持續將金融科技落實在服務中，希望為客戶帶來有感改變，提供更快速、貼切的服務。除了積極在Fintech領域布局區塊鏈、大數據、健康照護及人工智能，也同時與新創公司合作，推出理財機器人服務，朝著普惠、客製化的金融服務方向來努力，集團內的金融、電信服務更透過相互合作激盪出不少創新的火花，富邦將持續努力維持在金融科技領域的領先地位。\\xa0',\n",
       " None,\n",
       " 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bert_train.p',mode = 'wb') as pickle_file:\n",
    "    pickle.dump(train, pickle_file)\n",
    "\n",
    "with open('bert_dev.p',mode = 'wb') as pickle_file:\n",
    "    pickle.dump(dev, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################################################################################\n",
    "######################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_batch_size=6 ， 不然記憶體不足"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fb56d438ae8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'tmp/news_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb56c3de0f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
      "INFO:tensorflow:Writing example 0 of 36400\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: 39012\n",
      "INFO:tensorflow:tokens: [CLS] 鄭 貞 茂 ： 建 構 健 全 監 理 法 制 ， 引 領 金 融 科 技 創 新 發 展 moneydj 新 聞 2018 - 03 - 28 17 : 24 : 03 記 者 新 聞 中 心 報 導 2018 富 邦 金 控 暨 臺 大 財 金 系 金 融 論 壇 今 ( 28 ) 日 登 場 ， 由 臺 灣 大 學 管 理 學 院 副 院 長 陳 業 寧 引 言 ， 臺 灣 大 學 財 金 系 教 授 何 耕 宇 主 持 ， 金 管 會 副 主 委 鄭 貞 茂 、 源 鉑 資 本 創 辦 人 兼 執 行 長 胡 一 天 、 台 北 富 邦 銀 行 總 經 理 程 耀 輝 等 三 位 專 家 針 對 「 智 能 金 融 － 場 景 化 的 金 融 服 務 」 主 題 深 入 與 談 。 鄭 貞 茂 表 示 ， 為 鼓 勵 金 融 創 新 ， 金 管 會 積 極 建 構 有 利 於 金 融 科 技 創 新 和 發 展 的 環 境 與 產 業 共 同 前 進 ， 讓 有 益 社 會 的 創 新 金 融 商 品 或 服 務 能 萌 芽 發 展 ， 也 讓 業 者 有 機 會 實 現 及 測 試 好 的 創 新 構 想 ， 進 而 營 造 負 責 任 創 新 環 境 ， 為 金 融 消 費 者 提 供 充 足 的 保 障 。 鄭 貞 茂 指 出 ， 台 灣 在 今 年 1 月 公 布 「 金 融 科 技 發 展 與 創 新 實 驗 條 例 」 ， 成 為 全 球 第 一 個 以 成 文 法 推 動 監 理 沙 盒 的 國 家 ， 其 中 擬 參 考 國 外 虛 擬 沙 盒 ( virtual san ##db ##ox ) 作 法 ， 設 置 數 位 沙 盒 ， 規 劃 成 立 「 金 融 科 技 創 新 園 區 」 ， 作 為 監 理 沙 盒 的 前 置 實 驗 場 域 。 為 有 效 執 行 相 關 政 策 ， 今 年 2 月 也 成 立 了 「 金 融 科 技 發 展 與 創 新 中 心 」 ， 轄 下 並 設 立 創 新 發 展 組 及 園 區 發 展 組 。 鄭 貞 茂 強 調 ， 未 來 將 因 應 金 融 科 技 創 新 需 要 ， 建 構 健 全 的 監 理 法 制 ， 在 兼 顧 金 融 市 場 秩 序 及 消 費 者 權 益 下 ， 引 領 金 融 科 技 創 新 發 展 ， 營 造 一 個 負 責 任 創 新 的 環 境 ， 為 金 融 產 業 創 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 6972 6510 5744 8038 2456 3539 978 1059 4675 4415 3791 1169 8024 2471 7526 7032 6084 4906 2825 1201 3173 4634 2245 11911 3173 5472 8271 118 8140 118 8143 8126 131 8125 131 8140 6250 5442 3173 5472 704 2552 1841 2206 8271 2168 6930 7032 2971 3270 5637 1920 6512 7032 5143 7032 6084 6316 1883 791 113 8143 114 3189 4633 1842 8024 4507 5637 4124 1920 2119 5052 4415 2119 7368 1199 7368 7269 7376 3511 2180 2471 6241 8024 5637 4124 1920 2119 6512 7032 5143 3136 2956 862 5449 2126 712 2898 8024 7032 5052 3298 1199 712 1999 6972 6510 5744 510 3975 7058 6536 3315 1201 6794 782 1076 1822 6121 7269 5529 671 1921 510 1378 1266 2168 6930 7065 6121 5244 5195 4415 4923 5438 6740 5023 676 855 2201 2157 7036 2205 519 3255 5543 7032 6084 8025 1842 3250 1265 4638 7032 6084 3302 1243 520 712 7539 3918 1057 5645 6312 511 6972 6510 5744 6134 4850 8024 4158 7961 1252 7032 6084 1201 3173 8024 7032 5052 3298 4948 3513 2456 3539 3300 1164 3176 7032 6084 4906 2825 1201 3173 1469 4634 2245 4638 4472 1862 5645 4496 3511 1066 1398 1184 6868 8024 6366 3300 4660 4852 3298 4638 1201 3173 7032 6084 1555 1501 2772 3302 1243 5543 5846 5715 4634 2245 8024 738 6366 3511 5442 3300 3582 3298 2179 4412 1350 3947 6275 1962 4638 1201 3173 3539 2682 8024 6868 5445 4245 6863 6511 6519 818 1201 3173 4472 1862 8024 4158 7032 6084 3867 6527 5442 2990 897 1041 6639 4638 924 7397 511 6972 6510 5744 2900 1139 8024 1378 4124 1762 791 2399 122 3299 1062 2357 519 7032 6084 4906 2825 4634 2245 5645 1201 3173 2179 7710 3454 891 520 8024 2768 4158 1059 4413 5018 671 943 809 2768 3152 3791 2972 1240 4675 4415 3763 4665 4638 1751 2157 8024 1071 704 3093 1347 5440 1751 1912 5995 3093 3763 4665 113 12997 9542 9123 9747 114 868 3791 8024 6257 5390 3149 855 3763 4665 8024 6211 1205 2768 4989 519 7032 6084 4906 2825 1201 3173 1754 1281 520 8024 868 4158 4675 4415 3763 4665 4638 1184 5390 2179 7710 1842 1818 511 4158 3300 3126 1822 6121 4685 7302 3124 5032 8024 791 2399 123 3299 738 2768 4989 749 519 7032 6084 4906 2825 4634 2245 5645 1201 3173 704 2552 520 8024 6749 678 699 6257 4989 1201 3173 4634 2245 5175 1350 1754 1281 4634 2245 5175 511 6972 6510 5744 2485 6310 8024 3313 889 2200 1728 2746 7032 6084 4906 2825 1201 3173 7444 6206 8024 2456 3539 978 1059 4638 4675 4415 3791 1169 8024 1762 1076 7547 7032 6084 2356 1842 4914 2415 1350 3867 6527 5442 3609 4660 678 8024 2471 7526 7032 6084 4906 2825 1201 3173 4634 2245 8024 4245 6863 671 943 6511 6519 818 1201 3173 4638 4472 1862 8024 4158 7032 6084 4496 3511 1201 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: 8162\n",
      "INFO:tensorflow:tokens: [CLS] 陸 再 調 查 裁 定 ， 對 自 美 國 等 進 口 漿 粕 續 實 施 反 傾 銷 措 施 moneydj 新 聞 2018 - 04 - 20 10 : 59 : 47 記 者 新 聞 中 心 報 導 大 陸 商 務 部 今 ( 20 ) 日 公 佈 ， 關 於 原 產 於 美 國 、 加 拿 大 和 巴 西 的 進 口 漿 粕 反 傾 銷 措 施 的 再 調 查 裁 定 的 公 告 。 調 查 機 關 裁 定 ， 在 原 審 調 查 期 內 ， 原 產 於 美 國 、 加 拿 大 和 巴 西 進 口 漿 粕 的 傾 銷 行 為 導 致 中 國 大 陸 國 內 漿 粕 產 業 受 到 實 質 損 害 ， 傾 銷 與 實 質 損 害 之 間 存 在 因 果 關 係 。 調 查 機 關 決 定 ， 繼 續 按 照 大 陸 商 務 部 2014 年 第 18 號 公 告 內 容 實 施 反 傾 銷 措 施 。 大 陸 商 務 部 指 出 ， 根 據 中 國 反 傾 銷 條 例 及 商 務 部 《 執 行 世 界 貿 易 組 織 貿 易 救 濟 爭 端 裁 決 暫 行 規 則 》 規 定 ， 2017 年 8 月 25 日 ， 商 務 部 ( 以 下 稱 調 查 機 關 ) 發 佈 年 度 第 43 號 公 告 ， 決 定 通 過 再 調 查 執 行 世 界 貿 易 組 織 爭 端 解 決 機 構 關 於 加 拿 大 訴 中 國 漿 粕 產 品 反 傾 銷 措 施 案 專 家 組 報 告 的 裁 決 。 在 案 件 原 審 和 再 調 查 中 各 利 害 關 係 方 所 提 交 的 證 據 材 料 及 調 查 機 關 補 充 收 集 證 據 材 料 的 基 礎 上 ， 根 據 專 家 組 裁 決 ， 調 查 機 關 對 原 反 傾 銷 措 施 傾 銷 進 口 產 品 對 大 陸 國 內 產 業 同 類 產 品 價 格 的 影 響 、 傾 銷 進 口 產 品 與 國 內 產 業 損 害 之 間 的 因 果 關 係 、 其 他 已 知 因 素 對 中 國 國 內 產 業 的 影 響 等 問 題 進 行 再 調 查 。 根 據 再 調 查 結 果 並 依 據 反 傾 銷 條 例 和 《 執 行 爭 端 裁 決 暫 行 規 則 》 的 規 定 ， 調 查 機 關 作 出 再 調 查 裁 定 。 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 7380 1086 6310 3389 6161 2137 8024 2205 5632 5401 1751 5023 6868 1366 4043 5109 5265 2179 3177 1353 1005 7077 2974 3177 11911 3173 5472 8271 118 8147 118 8113 8108 131 8257 131 8264 6250 5442 3173 5472 704 2552 1841 2206 1920 7380 1555 1243 6956 791 113 8113 114 3189 1062 854 8024 7302 3176 1333 4496 3176 5401 1751 510 1217 2897 1920 1469 2349 6205 4638 6868 1366 4043 5109 1353 1005 7077 2974 3177 4638 1086 6310 3389 6161 2137 4638 1062 1440 511 6310 3389 3582 7302 6161 2137 8024 1762 1333 2182 6310 3389 3309 1058 8024 1333 4496 3176 5401 1751 510 1217 2897 1920 1469 2349 6205 6868 1366 4043 5109 4638 1005 7077 6121 4158 2206 5636 704 1751 1920 7380 1751 1058 4043 5109 4496 3511 1358 1168 2179 6549 3010 2154 8024 1005 7077 5645 2179 6549 3010 2154 722 7279 2100 1762 1728 3362 7302 913 511 6310 3389 3582 7302 3748 2137 8024 5262 5265 2902 4212 1920 7380 1555 1243 6956 8127 2399 5018 8123 5998 1062 1440 1058 2159 2179 3177 1353 1005 7077 2974 3177 511 1920 7380 1555 1243 6956 2900 1139 8024 3418 3087 704 1751 1353 1005 7077 3454 891 1350 1555 1243 6956 517 1822 6121 686 4518 6530 3211 5175 5251 6530 3211 3131 4089 4261 4999 6161 3748 3271 6121 6211 1179 518 6211 2137 8024 8109 2399 129 3299 8132 3189 8024 1555 1243 6956 113 809 678 4935 6310 3389 3582 7302 114 4634 854 2399 2428 5018 8250 5998 1062 1440 8024 3748 2137 6858 6882 1086 6310 3389 1822 6121 686 4518 6530 3211 5175 5251 4261 4999 6237 3748 3582 3539 7302 3176 1217 2897 1920 6260 704 1751 4043 5109 4496 1501 1353 1005 7077 2974 3177 3428 2201 2157 5175 1841 1440 4638 6161 3748 511 1762 3428 816 1333 2182 1469 1086 6310 3389 704 1392 1164 2154 7302 913 3175 2792 2990 769 4638 6349 3087 3332 3160 1350 6310 3389 3582 7302 6171 1041 3119 7415 6349 3087 3332 3160 4638 1825 4843 677 8024 3418 3087 2201 2157 5175 6161 3748 8024 6310 3389 3582 7302 2205 1333 1353 1005 7077 2974 3177 1005 7077 6868 1366 4496 1501 2205 1920 7380 1751 1058 4496 3511 1398 7546 4496 1501 1019 3419 4638 2512 7513 510 1005 7077 6868 1366 4496 1501 5645 1751 1058 4496 3511 3010 2154 722 7279 4638 1728 3362 7302 913 510 1071 800 2347 4761 1728 5162 2205 704 1751 1751 1058 4496 3511 4638 2512 7513 5023 1558 7539 6868 6121 1086 6310 3389 511 3418 3087 1086 6310 3389 5178 3362 699 898 3087 1353 1005 7077 3454 891 1469 517 1822 6121 4261 4999 6161 3748 3271 6121 6211 1179 518 4638 6211 2137 8024 6310 3389 3582 7302 868 1139 1086 6310 3389 6161 2137 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 1 (id = 1)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: 24645\n",
      "INFO:tensorflow:tokens: [CLS] 台 耀 標 下 dc ##b 蛋 白 質 藥 先 導 工 廠 ， 4 月 開 始 運 作 精 實 新 聞 2013 - 01 - 14 12 : 00 : 23 記 者 蕭 燕 翔 報 導 原 料 藥 廠 台 耀 ( 47 ##46 ) 投 標 生 技 中 心 ( dc ##b ) 招 標 確 定 得 標 ， 取 得 該 中 心 蛋 白 質 藥 品 的 先 導 工 廠 ； 台 耀 規 畫 ， 將 成 立 子 公 司 台 康 生 技 專 責 發 展 ， 新 公 司 資 本 額 預 估 約 1 , 500 萬 美 元 ， 台 耀 投 資 比 例 不 超 過 二 成 ， 生 技 中 心 除 技 術 及 人 員 轉 移 外 ， 預 料 也 將 是 主 要 股 東 ， 新 公 司 目 標 4 月 完 成 籌 資 、 開 始 運 作 ， 二 年 內 挑 戰 損 益 兩 平 。 台 耀 表 示 ， dc ##b 發 展 蛋 白 質 藥 品 已 有 一 段 時 間 ， 先 導 工 廠 也 達 一 定 基 礎 規 模 並 獲 必 要 認 證 及 執 照 ， 在 階 段 性 任 務 完 成 後 對 外 招 標 ， 最 後 由 台 耀 團 隊 得 標 。 根 據 台 耀 規 畫 ， 將 另 外 成 立 子 公 司 台 康 生 技 發 展 蛋 白 質 藥 品 ， 新 公 司 資 本 額 預 計 約 1 , 500 萬 美 元 ( 含 投 標 金 ) ， 其 中 台 耀 持 股 將 不 超 過 二 成 。 而 根 據 該 公 司 與 dc ##b 協 議 ， 雙 方 都 將 會 是 台 康 生 技 的 主 要 股 東 ， 其 他 則 將 向 生 醫 業 界 及 創 投 募 資 ， 預 計 4 月 資 金 到 位 、 正 式 開 始 運 作 。 台 耀 表 示 ， 未 來 台 康 生 技 公 司 將 延 攬 dc ##b 的 專 業 技 術 團 隊 ， 並 接 手 先 導 工 廠 廠 房 及 技 術 ， 未 來 該 公 司 客 戶 將 以 國 際 市 場 為 主 ， 但 也 會 兼 顧 扶 植 國 內 產 業 的 目 標 ， 初 期 希 望 能 擴 大 先 導 工 廠 的 出 貨 規 模 ， 二 年 內 挑 戰 損 益 兩 平 。 不 過 ， 台 耀 也 坦 言 ， 去 年 第 四 季 因 台 幣 升 值 及 違 反 水 汙 染 防 治 法 ， 部 分 產 線 遭 停 工 ， 12 月 中 下 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1378 5438 3560 678 8928 8204 6028 4635 6549 5973 1044 2206 2339 2449 8024 125 3299 7274 1993 6880 868 5125 2179 3173 5472 8138 118 8146 118 8122 8110 131 8136 131 8133 6250 5442 5941 4242 5425 1841 2206 1333 3160 5973 2449 1378 5438 113 8264 9340 114 2832 3560 4495 2825 704 2552 113 8928 8204 114 2875 3560 4825 2137 2533 3560 8024 1357 2533 6283 704 2552 6028 4635 6549 5973 1501 4638 1044 2206 2339 2449 8039 1378 5438 6211 4529 8024 2200 2768 4989 2094 1062 1385 1378 2434 4495 2825 2201 6519 4634 2245 8024 3173 1062 1385 6536 3315 7540 7521 844 5147 122 117 8195 5857 5401 1039 8024 1378 5438 2832 6536 3683 891 679 6631 6882 753 2768 8024 4495 2825 704 2552 7370 2825 6123 1350 782 1519 6752 4919 1912 8024 7521 3160 738 2200 3221 712 6206 5500 3346 8024 3173 1062 1385 4680 3560 125 3299 2130 2768 5092 6536 510 7274 1993 6880 868 8024 753 2399 1058 2904 2782 3010 4660 1060 2398 511 1378 5438 6134 4850 8024 8928 8204 4634 2245 6028 4635 6549 5973 1501 2347 3300 671 3667 3229 7279 8024 1044 2206 2339 2449 738 6888 671 2137 1825 4843 6211 3563 699 4363 2553 6206 6291 6349 1350 1822 4212 8024 1762 7389 3667 2595 818 1243 2130 2768 2527 2205 1912 2875 3560 8024 3297 2527 4507 1378 5438 1757 7386 2533 3560 511 3418 3087 1378 5438 6211 4529 8024 2200 1369 1912 2768 4989 2094 1062 1385 1378 2434 4495 2825 4634 2245 6028 4635 6549 5973 1501 8024 3173 1062 1385 6536 3315 7540 7521 6243 5147 122 117 8195 5857 5401 1039 113 1419 2832 3560 7032 114 8024 1071 704 1378 5438 2898 5500 2200 679 6631 6882 753 2768 511 5445 3418 3087 6283 1062 1385 5645 8928 8204 1295 6359 8024 7427 3175 6963 2200 3298 3221 1378 2434 4495 2825 4638 712 6206 5500 3346 8024 1071 800 1179 2200 1403 4495 7015 3511 4518 1350 1201 2832 1247 6536 8024 7521 6243 125 3299 6536 7032 1168 855 510 3633 2466 7274 1993 6880 868 511 1378 5438 6134 4850 8024 3313 889 1378 2434 4495 2825 1062 1385 2200 2454 3117 8928 8204 4638 2201 3511 2825 6123 1757 7386 8024 699 2970 2797 1044 2206 2339 2449 2449 2791 1350 2825 6123 8024 3313 889 6283 1062 1385 2145 2786 2200 809 1751 7396 2356 1842 4158 712 8024 852 738 3298 1076 7547 2820 3490 1751 1058 4496 3511 4638 4680 3560 8024 1159 3309 2361 3307 5543 3097 1920 1044 2206 2339 2449 4638 1139 6515 6211 3563 8024 753 2399 1058 2904 2782 3010 4660 1060 2398 511 679 6882 8024 1378 5438 738 1788 6241 8024 1343 2399 5018 1724 2108 1728 1378 2395 1285 966 1350 6889 1353 3717 3732 3381 7344 3780 3791 8024 6956 1146 4496 5221 6901 977 2339 8024 8110 3299 704 678 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: 39601\n",
      "INFO:tensorflow:tokens: [CLS] 三 星 大 絕 招 、 將 推 螢 幕 可 摺 疊 手 機 ？ 傳 明 年 1 月 亮 相 moneydj 新 聞 2015 - 09 - 16 08 : 23 : 23 記 者 陳 苓 報 導 三 星 電 子 東 山 再 起 的 終 極 兵 器 將 在 明 年 初 現 身 ？ 現 行 智 慧 機 區 隔 過 小 ， 難 以 吸 引 消 費 者 目 光 ， 有 爆 料 說 三 星 明 年 一 月 將 發 布 全 球 首 見 的 可 摺 疊 智 慧 機 ， 面 板 能 夠 像 書 本 一 樣 對 折 開 闔 ( 示 意 圖 見 此 ) 。 phone ##are ##na 、 g ##fo ##r ##ga ##mes 15 日 報 導 ， 三 星 救 買 氣 ， 用 塑 膠 取 代 玻 璃 基 板 ， 研 發 柔 性 面 板 ， 先 前 已 發 布 曲 型 螢 幕 機 galaxy s6 edge / edge + ， 問 題 是 曲 型 螢 幕 雖 酷 ， 卻 缺 乏 實 際 用 途 ， 噱 頭 成 分 居 多 。 三 星 再 進 一 步 研 發 可 摺 疊 面 板 ， 用 戶 能 收 合 大 面 板 ， 方 便 攜 帶 ， 具 有 高 度 實 用 性 。 爆 料 客 i 冰 宇 宙 在 微 博 發 文 ( 見 此 ) ， 三 星 或 許 會 在 明 年 一 月 發 布 「 pro ##j ##ec ##y valley 」 可 摺 疊 智 慧 機 ， 目 前 測 試 的 兩 個 版 本 分 別 搭 載 高 通 驍 龍 620 、 驍 龍 820 ， 新 機 內 建 3g ##b ram 、 mi ##sc ##ro sd 插 槽 、 電 池 不 可 拆 卸 。 i 冰 宇 宙 爆 料 具 有 一 定 準 確 度 ， 他 先 前 透 露 三 星 是 首 家 拿 到 高 通 驍 龍 820 樣 品 的 廠 商 ， 正 全 力 研 發 測 試 ； 他 也 曾 公 布 多 款 處 理 器 的 跑 分 評 比 ， 不 少 後 來 證 實 為 真 。 目 前 還 不 清 楚 三 星 摺 疊 機 會 是 什 麼 模 樣 ， 從 該 公 司 研 究 文 件 看 來 ， 顯 示 器 可 能 會 用 金 屬 網 格 ( metal me ##sh ) 觸 控 層 取 代 氧 化 [UNK] 錫 ( in ##dium ti ##n o ##xi ##de 、 it ##o ) 薄 膜 ， 如 此 一 來 ， 對 折 數 千 次 之 後 ， 摺 疊 區 域 面 板 都 能 正 常 運 作 。 it ##o 彎 折 後 容 易 損 壞 ， 不 適 合 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 676 3215 1920 5179 2875 510 2200 2972 6086 2391 1377 3045 4540 2797 3582 8043 1001 3209 2399 122 3299 778 4685 11911 3173 5472 8119 118 8141 118 8121 8142 131 8133 131 8133 6250 5442 7376 5725 1841 2206 676 3215 7442 2094 3346 2255 1086 6629 4638 5173 3513 1070 1690 2200 1762 3209 2399 1159 4412 6716 8043 4412 6121 3255 2716 3582 1281 7392 6882 2207 8024 7432 809 1429 2471 3867 6527 5442 4680 1045 8024 3300 4255 3160 6303 676 3215 3209 2399 671 3299 2200 4634 2357 1059 4413 7674 6210 4638 1377 3045 4540 3255 2716 3582 8024 7481 3352 5543 1917 1008 3292 3315 671 3564 2205 2835 7274 7298 113 4850 2692 1756 6210 3634 114 511 8922 10305 8374 510 149 10261 8180 8676 13060 8115 3189 1841 2206 8024 676 3215 3131 6525 3706 8024 4500 1848 5608 1357 807 4390 4461 1825 3352 8024 4777 4634 3382 2595 7481 3352 8024 1044 1184 2347 4634 2357 3289 1798 6086 2391 3582 8547 10470 9720 120 9720 116 8024 1558 7539 3221 3289 1798 6086 2391 7426 6999 8024 1320 5375 726 2179 7396 4500 6854 8024 1694 7531 2768 1146 2233 1914 511 676 3215 1086 6868 671 3635 4777 4634 1377 3045 4540 7481 3352 8024 4500 2786 5543 3119 1394 1920 7481 3352 8024 3175 912 3108 2380 8024 1072 3300 7770 2428 2179 4500 2595 511 4255 3160 2145 151 1102 2126 2136 1762 2544 1300 4634 3152 113 6210 3634 114 8024 676 3215 2772 6258 3298 1762 3209 2399 671 3299 4634 2357 519 8376 8334 9587 8179 11994 520 1377 3045 4540 3255 2716 3582 8024 4680 1184 3947 6275 4638 1060 943 4276 3315 1146 1162 3022 6734 7770 6858 7707 7983 11078 510 7707 7983 10398 8024 3173 3582 1058 2456 8456 8204 9270 510 10551 10203 8607 9201 2991 3553 510 7442 3737 679 1377 2858 1319 511 151 1102 2126 2136 4255 3160 1072 3300 671 2137 3976 4825 2428 8024 800 1044 1184 6851 7463 676 3215 3221 7674 2157 2897 1168 7770 6858 7707 7983 10398 3564 1501 4638 2449 1555 8024 3633 1059 1213 4777 4634 3947 6275 8039 800 738 3295 1062 2357 1914 3621 5993 4415 1690 4638 6651 1146 6268 3683 8024 679 2208 2527 889 6349 2179 4158 4696 511 4680 1184 6917 679 3926 3504 676 3215 3045 4540 3582 3298 3221 784 7938 3563 3564 8024 2537 6283 1062 1385 4777 4955 3152 816 4692 889 8024 7549 4850 1690 1377 5543 3298 4500 7032 2253 5206 3419 113 13259 8450 8613 114 6240 2971 2251 1357 807 3709 1265 100 7095 113 8217 12787 9654 8171 157 10201 8510 510 8233 8167 114 5946 5606 8024 1963 3634 671 889 8024 2205 2835 3149 1283 3613 722 2527 8024 3045 4540 1281 1818 7481 3352 6963 5543 3633 2382 6880 868 511 8233 8167 2494 2835 2527 2159 3211 3010 1889 8024 679 6900 1394 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: 43726\n",
      "INFO:tensorflow:tokens: [CLS] 和 泰 車 攻 中 古 車 網 購 市 場 ， @ bc 好 車 網 12 / 4 上 線 moneydj 新 聞 2014 - 12 - 03 10 : 12 : 38 記 者 新 聞 中 心 報 導 和 泰 車 ( 220 ##7 ) 積 極 搶 攻 中 古 車 網 路 交 易 市 場 。 和 泰 車 表 示 ， 適 逢 中 古 車 購 車 的 年 末 高 峰 ， 「 @ bc 好 車 網 」 將 於 明 ( 4 ) 日 正 式 上 線 ， 希 望 透 過 創 新 且 健 全 的 線 上 平 台 ， 搭 配 有 認 證 服 務 的 實 體 據 點 作 為 後 盾 ， 開 啟 中 古 車 網 路 交 易 新 時 代 。 2014 年 中 古 車 總 交 易 過 戶 數 上 看 76 萬 ， 預 計 將 創 下 近 九 年 來 新 高 。 和 泰 車 指 出 ， 為 消 彌 消 費 者 購 買 中 古 車 的 不 安 與 擔 憂 ， 讓 購 買 中 古 車 更 加 輕 鬆 愉 快 ， 旗 下 @ bc 好 車 網 將 主 打 包 括 巨 量 權 威 行 情 、 優 質 原 廠 車 源 、 免 費 預 約 查 估 以 及 優 惠 好 康 活 動 等 四 大 服 務 特 點 。 和 泰 車 指 出 ， @ bc 好 車 網 網 羅 中 古 車 市 場 的 收 購 實 績 ， 致 力 架 構 公 正 性 的 免 費 行 情 查 詢 系 統 ， 讓 市 場 價 格 透 明 化 ， 幫 助 買 賣 雙 方 在 交 易 時 更 容 易 達 成 共 識 ； 為 降 低 買 家 對 中 古 車 車 況 的 擔 憂 ， @ bc 好 車 網 並 同 步 與 各 大 品 牌 原 廠 認 證 中 古 車 及 認 證 聯 盟 ( 如 toyota 認 證 中 古 車 、 hot 大 聯 盟 等 ) 合 作 ， 提 供 優 質 且 量 多 的 中 古 車 ， 讓 消 費 者 選 擇 更 多 ， 買 得 更 安 心 。 除 此 之 外 ， 賣 家 只 要 登 入 車 輛 資 訊 ， @ bc 好 車 網 即 會 委 派 特 約 的 專 業 預 約 查 估 團 隊 提 供 服 務 ， 且 完 全 免 費 ， 讓 賣 家 輕 鬆 掌 握 愛 車 行 情 。 另 為 歡 慶 開 站 ， @ bc 好 車 網 並 推 出 多 重 好 禮 ， 除 了 提 供 32 台 9 成 9 新 日 本 原 裝 優 質 好 車 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1469 3805 6722 3122 704 1367 6722 5206 6554 2356 1842 8024 137 10954 1962 6722 5206 8110 120 125 677 5221 11911 3173 5472 8127 118 8110 118 8140 8108 131 8110 131 8218 6250 5442 3173 5472 704 2552 1841 2206 1469 3805 6722 113 8796 8161 114 4948 3513 3024 3122 704 1367 6722 5206 6662 769 3211 2356 1842 511 1469 3805 6722 6134 4850 8024 6900 6864 704 1367 6722 6554 6722 4638 2399 3314 7770 2292 8024 519 137 10954 1962 6722 5206 520 2200 3176 3209 113 125 114 3189 3633 2466 677 5221 8024 2361 3307 6851 6882 1201 3173 684 978 1059 4638 5221 677 2398 1378 8024 3022 6981 3300 6291 6349 3302 1243 4638 2179 7768 3087 7953 868 4158 2527 4688 8024 7274 1564 704 1367 6722 5206 6662 769 3211 3173 3229 807 511 8127 2399 704 1367 6722 5244 769 3211 6882 2786 3149 677 4692 8399 5857 8024 7521 6243 2200 1201 678 6818 736 2399 889 3173 7770 511 1469 3805 6722 2900 1139 8024 4158 3867 2493 3867 6527 5442 6554 6525 704 1367 6722 4638 679 2128 5645 3085 2726 8024 6366 6554 6525 704 1367 6722 3291 1217 6738 7777 2690 2571 8024 3186 678 137 10954 1962 6722 5206 2200 712 2802 1259 2886 2342 7030 3609 2014 6121 2658 510 1032 6549 1333 2449 6722 3975 510 1048 6527 7521 5147 3389 844 809 1350 1032 2669 1962 2434 3833 1240 5023 1724 1920 3302 1243 4294 7953 511 1469 3805 6722 2900 1139 8024 137 10954 1962 6722 5206 5206 5397 704 1367 6722 2356 1842 4638 3119 6554 2179 5245 8024 5636 1213 3373 3539 1062 3633 2595 4638 1048 6527 6121 2658 3389 6273 5143 5186 8024 6366 2356 1842 1019 3419 6851 3209 1265 8024 2396 1221 6525 6546 7427 3175 1762 769 3211 3229 3291 2159 3211 6888 2768 1066 6352 8039 4158 7360 856 6525 2157 2205 704 1367 6722 6722 3785 4638 3085 2726 8024 137 10954 1962 6722 5206 699 1398 3635 5645 1392 1920 1501 4277 1333 2449 6291 6349 704 1367 6722 1350 6291 6349 5474 4673 113 1963 10632 6291 6349 704 1367 6722 510 9286 1920 5474 4673 5023 114 1394 868 8024 2990 897 1032 6549 684 7030 1914 4638 704 1367 6722 8024 6366 3867 6527 5442 6908 3079 3291 1914 8024 6525 2533 3291 2128 2552 511 7370 3634 722 1912 8024 6546 2157 1372 6206 4633 1057 6722 6739 6536 6244 8024 137 10954 1962 6722 5206 1315 3298 1999 3836 4294 5147 4638 2201 3511 7521 5147 3389 844 1757 7386 2990 897 3302 1243 8024 684 2130 1059 1048 6527 8024 6366 6546 2157 6738 7777 2958 2995 2695 6722 6121 2658 511 1369 4158 3631 2723 7274 4991 8024 137 10954 1962 6722 5206 699 2972 1139 1914 7028 1962 4891 8024 7370 749 2990 897 8211 1378 130 2768 130 3173 3189 3315 1333 6172 1032 6549 1962 6722 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:Writing example 10000 of 36400\n",
      "INFO:tensorflow:Writing example 20000 of 36400\n",
      "INFO:tensorflow:Writing example 30000 of 36400\n",
      "INFO:tensorflow:***** Running training *****\n",
      "INFO:tensorflow:  Num examples = 36400\n",
      "INFO:tensorflow:  Batch size = 6\n",
      "INFO:tensorflow:  Num steps = 18200\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running train on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (6, 512)\n",
      "INFO:tensorflow:  name = input_mask, shape = (6, 512)\n",
      "INFO:tensorflow:  name = is_real_example, shape = (6,)\n",
      "INFO:tensorflow:  name = label_ids, shape = (6,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (6, 512)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (21128, 768)\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = output_weights:0, shape = (2, 768)\n",
      "INFO:tensorflow:  name = output_bias:0, shape = (2,)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-06-24 15:07:31.144171: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2019-06-24 15:07:31.573442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:07:00.0\n",
      "totalMemory: 10.92GiB freeMemory: 10.76GiB\n",
      "2019-06-24 15:07:31.811406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:08:00.0\n",
      "totalMemory: 10.92GiB freeMemory: 10.76GiB\n",
      "2019-06-24 15:07:32.044810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 2 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:0c:00.0\n",
      "totalMemory: 10.92GiB freeMemory: 10.76GiB\n",
      "2019-06-24 15:07:32.300917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 3 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:0e:00.0\n",
      "totalMemory: 10.92GiB freeMemory: 10.76GiB\n",
      "2019-06-24 15:07:32.309218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2019-06-24 15:07:33.424301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-24 15:07:33.424359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 1 2 3 \n",
      "2019-06-24 15:07:33.424374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N Y Y Y \n",
      "2019-06-24 15:07:33.424385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 1:   Y N Y Y \n",
      "2019-06-24 15:07:33.424396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 2:   Y Y N Y \n",
      "2019-06-24 15:07:33.424406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 3:   Y Y Y N \n",
      "2019-06-24 15:07:33.425265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10405 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:07:00.0, compute capability: 6.1)\n",
      "2019-06-24 15:07:33.578702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10405 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)\n",
      "2019-06-24 15:07:33.735381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10405 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:0c:00.0, compute capability: 6.1)\n",
      "2019-06-24 15:07:33.890738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10405 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:0e:00.0, compute capability: 6.1)\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.04371\n",
      "INFO:tensorflow:examples/sec: 12.2622\n",
      "INFO:tensorflow:global_step/sec: 2.21492\n",
      "INFO:tensorflow:examples/sec: 13.2895\n",
      "INFO:tensorflow:global_step/sec: 2.19374\n",
      "INFO:tensorflow:examples/sec: 13.1625\n",
      "INFO:tensorflow:global_step/sec: 2.17621\n",
      "INFO:tensorflow:examples/sec: 13.0573\n",
      "INFO:tensorflow:global_step/sec: 2.17146\n",
      "INFO:tensorflow:examples/sec: 13.0288\n",
      "INFO:tensorflow:global_step/sec: 2.17649\n",
      "INFO:tensorflow:examples/sec: 13.0589\n",
      "INFO:tensorflow:global_step/sec: 2.17333\n",
      "INFO:tensorflow:examples/sec: 13.04\n",
      "INFO:tensorflow:global_step/sec: 2.17241\n",
      "INFO:tensorflow:examples/sec: 13.0344\n",
      "INFO:tensorflow:global_step/sec: 2.16608\n",
      "INFO:tensorflow:examples/sec: 12.9965\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.46886\n",
      "INFO:tensorflow:examples/sec: 8.81318\n",
      "INFO:tensorflow:global_step/sec: 2.20955\n",
      "INFO:tensorflow:examples/sec: 13.2573\n",
      "INFO:tensorflow:global_step/sec: 2.17472\n",
      "INFO:tensorflow:examples/sec: 13.0483\n",
      "INFO:tensorflow:global_step/sec: 2.16983\n",
      "INFO:tensorflow:examples/sec: 13.019\n",
      "INFO:tensorflow:global_step/sec: 2.17163\n",
      "INFO:tensorflow:examples/sec: 13.0298\n",
      "INFO:tensorflow:global_step/sec: 2.16746\n",
      "INFO:tensorflow:examples/sec: 13.0048\n",
      "INFO:tensorflow:global_step/sec: 2.16252\n",
      "INFO:tensorflow:examples/sec: 12.9751\n",
      "INFO:tensorflow:global_step/sec: 2.17231\n",
      "INFO:tensorflow:examples/sec: 13.0339\n",
      "INFO:tensorflow:global_step/sec: 2.17917\n",
      "INFO:tensorflow:examples/sec: 13.075\n",
      "INFO:tensorflow:global_step/sec: 2.17595\n",
      "INFO:tensorflow:examples/sec: 13.0557\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.45792\n",
      "INFO:tensorflow:examples/sec: 8.7475\n",
      "INFO:tensorflow:global_step/sec: 2.2111\n",
      "INFO:tensorflow:examples/sec: 13.2666\n",
      "INFO:tensorflow:global_step/sec: 2.16425\n",
      "INFO:tensorflow:examples/sec: 12.9855\n",
      "INFO:tensorflow:global_step/sec: 2.17425\n",
      "INFO:tensorflow:examples/sec: 13.0455\n",
      "INFO:tensorflow:global_step/sec: 2.16891\n",
      "INFO:tensorflow:examples/sec: 13.0135\n",
      "INFO:tensorflow:global_step/sec: 2.15644\n",
      "INFO:tensorflow:examples/sec: 12.9387\n",
      "INFO:tensorflow:global_step/sec: 2.16624\n",
      "INFO:tensorflow:examples/sec: 12.9974\n",
      "INFO:tensorflow:global_step/sec: 2.16571\n",
      "INFO:tensorflow:examples/sec: 12.9943\n",
      "INFO:tensorflow:global_step/sec: 2.17204\n",
      "INFO:tensorflow:examples/sec: 13.0322\n",
      "INFO:tensorflow:global_step/sec: 2.1783\n",
      "INFO:tensorflow:examples/sec: 13.0698\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.44464\n",
      "INFO:tensorflow:examples/sec: 8.66786\n",
      "INFO:tensorflow:global_step/sec: 2.21321\n",
      "INFO:tensorflow:examples/sec: 13.2793\n",
      "INFO:tensorflow:global_step/sec: 2.1733\n",
      "INFO:tensorflow:examples/sec: 13.0398\n",
      "INFO:tensorflow:global_step/sec: 2.17553\n",
      "INFO:tensorflow:examples/sec: 13.0532\n",
      "INFO:tensorflow:global_step/sec: 2.16643\n",
      "INFO:tensorflow:examples/sec: 12.9986\n",
      "INFO:tensorflow:global_step/sec: 2.17506\n",
      "INFO:tensorflow:examples/sec: 13.0503\n",
      "INFO:tensorflow:global_step/sec: 2.1738\n",
      "INFO:tensorflow:examples/sec: 13.0428\n",
      "INFO:tensorflow:global_step/sec: 2.17192\n",
      "INFO:tensorflow:examples/sec: 13.0315\n",
      "INFO:tensorflow:global_step/sec: 2.17788\n",
      "INFO:tensorflow:examples/sec: 13.0673\n",
      "INFO:tensorflow:global_step/sec: 2.17782\n",
      "INFO:tensorflow:examples/sec: 13.0669\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.43171\n",
      "INFO:tensorflow:examples/sec: 8.59025\n",
      "INFO:tensorflow:global_step/sec: 2.21419\n",
      "INFO:tensorflow:examples/sec: 13.2851\n",
      "INFO:tensorflow:global_step/sec: 2.16485\n",
      "INFO:tensorflow:examples/sec: 12.9891\n",
      "INFO:tensorflow:global_step/sec: 2.16486\n",
      "INFO:tensorflow:examples/sec: 12.9892\n",
      "INFO:tensorflow:global_step/sec: 2.17072\n",
      "INFO:tensorflow:examples/sec: 13.0243\n",
      "INFO:tensorflow:global_step/sec: 2.17134\n",
      "INFO:tensorflow:examples/sec: 13.0281\n",
      "INFO:tensorflow:global_step/sec: 2.16067\n",
      "INFO:tensorflow:examples/sec: 12.964\n",
      "INFO:tensorflow:global_step/sec: 2.16848\n",
      "INFO:tensorflow:examples/sec: 13.0109\n",
      "INFO:tensorflow:global_step/sec: 2.17951\n",
      "INFO:tensorflow:examples/sec: 13.077\n",
      "INFO:tensorflow:global_step/sec: 2.17337\n",
      "INFO:tensorflow:examples/sec: 13.0402\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.44836\n",
      "INFO:tensorflow:examples/sec: 8.69016\n",
      "INFO:tensorflow:global_step/sec: 2.21311\n",
      "INFO:tensorflow:examples/sec: 13.2787\n",
      "INFO:tensorflow:global_step/sec: 2.16525\n",
      "INFO:tensorflow:examples/sec: 12.9915\n",
      "INFO:tensorflow:global_step/sec: 2.17142\n",
      "INFO:tensorflow:examples/sec: 13.0285\n",
      "INFO:tensorflow:global_step/sec: 2.16237\n",
      "INFO:tensorflow:examples/sec: 12.9742\n",
      "INFO:tensorflow:global_step/sec: 2.17605\n",
      "INFO:tensorflow:examples/sec: 13.0563\n",
      "INFO:tensorflow:global_step/sec: 2.16477\n",
      "INFO:tensorflow:examples/sec: 12.9886\n",
      "INFO:tensorflow:global_step/sec: 2.17051\n",
      "INFO:tensorflow:examples/sec: 13.023\n",
      "INFO:tensorflow:global_step/sec: 2.17204\n",
      "INFO:tensorflow:examples/sec: 13.0322\n",
      "INFO:tensorflow:global_step/sec: 2.1781\n",
      "INFO:tensorflow:examples/sec: 13.0686\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.32676\n",
      "INFO:tensorflow:examples/sec: 7.96058\n",
      "INFO:tensorflow:global_step/sec: 2.21725\n",
      "INFO:tensorflow:examples/sec: 13.3035\n",
      "INFO:tensorflow:global_step/sec: 2.1769\n",
      "INFO:tensorflow:examples/sec: 13.0614\n",
      "INFO:tensorflow:global_step/sec: 2.16506\n",
      "INFO:tensorflow:examples/sec: 12.9903\n",
      "INFO:tensorflow:global_step/sec: 2.17296\n",
      "INFO:tensorflow:examples/sec: 13.0378\n",
      "INFO:tensorflow:global_step/sec: 2.1759\n",
      "INFO:tensorflow:examples/sec: 13.0554\n",
      "INFO:tensorflow:global_step/sec: 2.17669\n",
      "INFO:tensorflow:examples/sec: 13.0601\n",
      "INFO:tensorflow:global_step/sec: 2.16973\n",
      "INFO:tensorflow:examples/sec: 13.0184\n",
      "INFO:tensorflow:global_step/sec: 2.17205\n",
      "INFO:tensorflow:examples/sec: 13.0323\n",
      "INFO:tensorflow:global_step/sec: 2.17758\n",
      "INFO:tensorflow:examples/sec: 13.0655\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.42521\n",
      "INFO:tensorflow:examples/sec: 8.55126\n",
      "INFO:tensorflow:global_step/sec: 2.21495\n",
      "INFO:tensorflow:examples/sec: 13.2897\n",
      "INFO:tensorflow:global_step/sec: 2.17387\n",
      "INFO:tensorflow:examples/sec: 13.0432\n",
      "INFO:tensorflow:global_step/sec: 2.17347\n",
      "INFO:tensorflow:examples/sec: 13.0408\n",
      "INFO:tensorflow:global_step/sec: 2.16605\n",
      "INFO:tensorflow:examples/sec: 12.9963\n",
      "INFO:tensorflow:global_step/sec: 2.15852\n",
      "INFO:tensorflow:examples/sec: 12.9511\n",
      "INFO:tensorflow:global_step/sec: 2.17056\n",
      "INFO:tensorflow:examples/sec: 13.0233\n",
      "INFO:tensorflow:global_step/sec: 2.16885\n",
      "INFO:tensorflow:examples/sec: 13.0131\n",
      "INFO:tensorflow:global_step/sec: 2.17601\n",
      "INFO:tensorflow:examples/sec: 13.056\n",
      "INFO:tensorflow:global_step/sec: 2.17087\n",
      "INFO:tensorflow:examples/sec: 13.0252\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.45733\n",
      "INFO:tensorflow:examples/sec: 8.74396\n",
      "INFO:tensorflow:global_step/sec: 2.21131\n",
      "INFO:tensorflow:examples/sec: 13.2679\n",
      "INFO:tensorflow:global_step/sec: 2.17278\n",
      "INFO:tensorflow:examples/sec: 13.0367\n",
      "INFO:tensorflow:global_step/sec: 2.16703\n",
      "INFO:tensorflow:examples/sec: 13.0022\n",
      "INFO:tensorflow:global_step/sec: 2.16844\n",
      "INFO:tensorflow:examples/sec: 13.0106\n",
      "INFO:tensorflow:global_step/sec: 2.16994\n",
      "INFO:tensorflow:examples/sec: 13.0196\n",
      "INFO:tensorflow:global_step/sec: 2.17577\n",
      "INFO:tensorflow:examples/sec: 13.0546\n",
      "INFO:tensorflow:global_step/sec: 2.17655\n",
      "INFO:tensorflow:examples/sec: 13.0593\n",
      "INFO:tensorflow:global_step/sec: 2.17488\n",
      "INFO:tensorflow:examples/sec: 13.0493\n",
      "INFO:tensorflow:global_step/sec: 2.17894\n",
      "INFO:tensorflow:examples/sec: 13.0737\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.46394\n",
      "INFO:tensorflow:examples/sec: 8.78363\n",
      "INFO:tensorflow:global_step/sec: 2.21299\n",
      "INFO:tensorflow:examples/sec: 13.2779\n",
      "INFO:tensorflow:global_step/sec: 2.17791\n",
      "INFO:tensorflow:examples/sec: 13.0675\n",
      "INFO:tensorflow:global_step/sec: 2.17749\n",
      "INFO:tensorflow:examples/sec: 13.065\n",
      "INFO:tensorflow:global_step/sec: 2.16659\n",
      "INFO:tensorflow:examples/sec: 12.9996\n",
      "INFO:tensorflow:global_step/sec: 2.17514\n",
      "INFO:tensorflow:examples/sec: 13.0508\n",
      "INFO:tensorflow:global_step/sec: 2.17736\n",
      "INFO:tensorflow:examples/sec: 13.0642\n",
      "INFO:tensorflow:global_step/sec: 2.17762\n",
      "INFO:tensorflow:examples/sec: 13.0657\n",
      "INFO:tensorflow:global_step/sec: 2.17806\n",
      "INFO:tensorflow:examples/sec: 13.0683\n",
      "INFO:tensorflow:global_step/sec: 2.17904\n",
      "INFO:tensorflow:examples/sec: 13.0743\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.42659\n",
      "INFO:tensorflow:examples/sec: 8.55956\n",
      "INFO:tensorflow:global_step/sec: 2.21514\n",
      "INFO:tensorflow:examples/sec: 13.2908\n",
      "INFO:tensorflow:global_step/sec: 2.1721\n",
      "INFO:tensorflow:examples/sec: 13.0326\n",
      "INFO:tensorflow:global_step/sec: 2.17394\n",
      "INFO:tensorflow:examples/sec: 13.0436\n",
      "INFO:tensorflow:global_step/sec: 2.17167\n",
      "INFO:tensorflow:examples/sec: 13.03\n",
      "INFO:tensorflow:global_step/sec: 2.177\n",
      "INFO:tensorflow:examples/sec: 13.062\n",
      "INFO:tensorflow:global_step/sec: 2.17462\n",
      "INFO:tensorflow:examples/sec: 13.0477\n",
      "INFO:tensorflow:global_step/sec: 2.17258\n",
      "INFO:tensorflow:examples/sec: 13.0355\n",
      "INFO:tensorflow:global_step/sec: 2.17488\n",
      "INFO:tensorflow:examples/sec: 13.0493\n",
      "INFO:tensorflow:global_step/sec: 2.17815\n",
      "INFO:tensorflow:examples/sec: 13.0689\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.45389\n",
      "INFO:tensorflow:examples/sec: 8.72334\n",
      "INFO:tensorflow:global_step/sec: 2.21265\n",
      "INFO:tensorflow:examples/sec: 13.2759\n",
      "INFO:tensorflow:global_step/sec: 2.17705\n",
      "INFO:tensorflow:examples/sec: 13.0623\n",
      "INFO:tensorflow:global_step/sec: 2.16941\n",
      "INFO:tensorflow:examples/sec: 13.0165\n",
      "INFO:tensorflow:global_step/sec: 2.16708\n",
      "INFO:tensorflow:examples/sec: 13.0025\n",
      "INFO:tensorflow:global_step/sec: 2.17056\n",
      "INFO:tensorflow:examples/sec: 13.0234\n",
      "INFO:tensorflow:global_step/sec: 2.16451\n",
      "INFO:tensorflow:examples/sec: 12.9871\n",
      "INFO:tensorflow:global_step/sec: 2.17127\n",
      "INFO:tensorflow:examples/sec: 13.0276\n",
      "INFO:tensorflow:global_step/sec: 2.1701\n",
      "INFO:tensorflow:examples/sec: 13.0206\n",
      "INFO:tensorflow:global_step/sec: 2.17518\n",
      "INFO:tensorflow:examples/sec: 13.0511\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.36429\n",
      "INFO:tensorflow:examples/sec: 8.18574\n",
      "INFO:tensorflow:global_step/sec: 2.21826\n",
      "INFO:tensorflow:examples/sec: 13.3095\n",
      "INFO:tensorflow:global_step/sec: 2.18584\n",
      "INFO:tensorflow:examples/sec: 13.115\n",
      "INFO:tensorflow:global_step/sec: 2.16806\n",
      "INFO:tensorflow:examples/sec: 13.0083\n",
      "INFO:tensorflow:global_step/sec: 2.17714\n",
      "INFO:tensorflow:examples/sec: 13.0628\n",
      "INFO:tensorflow:global_step/sec: 2.17523\n",
      "INFO:tensorflow:examples/sec: 13.0514\n",
      "INFO:tensorflow:global_step/sec: 2.17991\n",
      "INFO:tensorflow:examples/sec: 13.0794\n",
      "INFO:tensorflow:global_step/sec: 2.17639\n",
      "INFO:tensorflow:examples/sec: 13.0584\n",
      "INFO:tensorflow:global_step/sec: 2.17652\n",
      "INFO:tensorflow:examples/sec: 13.0591\n",
      "INFO:tensorflow:global_step/sec: 2.1745\n",
      "INFO:tensorflow:examples/sec: 13.047\n",
      "INFO:tensorflow:Saving checkpoints for 13000 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.40524\n",
      "INFO:tensorflow:examples/sec: 8.43146\n",
      "INFO:tensorflow:global_step/sec: 2.21701\n",
      "INFO:tensorflow:examples/sec: 13.3021\n",
      "INFO:tensorflow:global_step/sec: 2.17301\n",
      "INFO:tensorflow:examples/sec: 13.038\n",
      "INFO:tensorflow:global_step/sec: 2.17863\n",
      "INFO:tensorflow:examples/sec: 13.0718\n",
      "INFO:tensorflow:global_step/sec: 2.17001\n",
      "INFO:tensorflow:examples/sec: 13.02\n",
      "INFO:tensorflow:global_step/sec: 2.1693\n",
      "INFO:tensorflow:examples/sec: 13.0158\n",
      "INFO:tensorflow:global_step/sec: 2.17628\n",
      "INFO:tensorflow:examples/sec: 13.0577\n",
      "INFO:tensorflow:global_step/sec: 2.17693\n",
      "INFO:tensorflow:examples/sec: 13.0616\n",
      "INFO:tensorflow:global_step/sec: 2.17897\n",
      "INFO:tensorflow:examples/sec: 13.0738\n",
      "INFO:tensorflow:global_step/sec: 2.17458\n",
      "INFO:tensorflow:examples/sec: 13.0475\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.35498\n",
      "INFO:tensorflow:examples/sec: 8.12988\n",
      "INFO:tensorflow:global_step/sec: 2.21892\n",
      "INFO:tensorflow:examples/sec: 13.3135\n",
      "INFO:tensorflow:global_step/sec: 2.1756\n",
      "INFO:tensorflow:examples/sec: 13.0536\n",
      "INFO:tensorflow:global_step/sec: 2.16483\n",
      "INFO:tensorflow:examples/sec: 12.989\n",
      "INFO:tensorflow:global_step/sec: 2.17416\n",
      "INFO:tensorflow:examples/sec: 13.045\n",
      "INFO:tensorflow:global_step/sec: 2.17572\n",
      "INFO:tensorflow:examples/sec: 13.0543\n",
      "INFO:tensorflow:global_step/sec: 2.17633\n",
      "INFO:tensorflow:examples/sec: 13.058\n",
      "INFO:tensorflow:global_step/sec: 2.17718\n",
      "INFO:tensorflow:examples/sec: 13.0631\n",
      "INFO:tensorflow:global_step/sec: 2.1721\n",
      "INFO:tensorflow:examples/sec: 13.0326\n",
      "INFO:tensorflow:global_step/sec: 2.17467\n",
      "INFO:tensorflow:examples/sec: 13.048\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.45678\n",
      "INFO:tensorflow:examples/sec: 8.74069\n",
      "INFO:tensorflow:global_step/sec: 2.21506\n",
      "INFO:tensorflow:examples/sec: 13.2904\n",
      "INFO:tensorflow:global_step/sec: 2.17351\n",
      "INFO:tensorflow:examples/sec: 13.0411\n",
      "INFO:tensorflow:global_step/sec: 2.17558\n",
      "INFO:tensorflow:examples/sec: 13.0535\n",
      "INFO:tensorflow:global_step/sec: 2.17369\n",
      "INFO:tensorflow:examples/sec: 13.0421\n",
      "INFO:tensorflow:global_step/sec: 2.17033\n",
      "INFO:tensorflow:examples/sec: 13.022\n",
      "INFO:tensorflow:global_step/sec: 2.17373\n",
      "INFO:tensorflow:examples/sec: 13.0424\n",
      "INFO:tensorflow:global_step/sec: 2.17515\n",
      "INFO:tensorflow:examples/sec: 13.0509\n",
      "INFO:tensorflow:global_step/sec: 2.17699\n",
      "INFO:tensorflow:examples/sec: 13.0619\n",
      "INFO:tensorflow:global_step/sec: 2.17982\n",
      "INFO:tensorflow:examples/sec: 13.0789\n",
      "INFO:tensorflow:Saving checkpoints for 16000 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.46071\n",
      "INFO:tensorflow:examples/sec: 8.76426\n",
      "INFO:tensorflow:global_step/sec: 2.21508\n",
      "INFO:tensorflow:examples/sec: 13.2905\n",
      "INFO:tensorflow:global_step/sec: 2.16983\n",
      "INFO:tensorflow:examples/sec: 13.019\n",
      "INFO:tensorflow:global_step/sec: 2.17867\n",
      "INFO:tensorflow:examples/sec: 13.072\n",
      "INFO:tensorflow:global_step/sec: 2.17105\n",
      "INFO:tensorflow:examples/sec: 13.0263\n",
      "INFO:tensorflow:global_step/sec: 2.1764\n",
      "INFO:tensorflow:examples/sec: 13.0584\n",
      "INFO:tensorflow:global_step/sec: 2.17552\n",
      "INFO:tensorflow:examples/sec: 13.0531\n",
      "INFO:tensorflow:global_step/sec: 2.17434\n",
      "INFO:tensorflow:examples/sec: 13.0461\n",
      "INFO:tensorflow:global_step/sec: 2.17584\n",
      "INFO:tensorflow:examples/sec: 13.055\n",
      "INFO:tensorflow:global_step/sec: 2.17608\n",
      "INFO:tensorflow:examples/sec: 13.0565\n",
      "INFO:tensorflow:Saving checkpoints for 17000 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.44444\n",
      "INFO:tensorflow:examples/sec: 8.66665\n",
      "INFO:tensorflow:global_step/sec: 2.21574\n",
      "INFO:tensorflow:examples/sec: 13.2944\n",
      "INFO:tensorflow:global_step/sec: 2.17533\n",
      "INFO:tensorflow:examples/sec: 13.052\n",
      "INFO:tensorflow:global_step/sec: 2.1732\n",
      "INFO:tensorflow:examples/sec: 13.0392\n",
      "INFO:tensorflow:global_step/sec: 2.17382\n",
      "INFO:tensorflow:examples/sec: 13.0429\n",
      "INFO:tensorflow:global_step/sec: 2.17971\n",
      "INFO:tensorflow:examples/sec: 13.0783\n",
      "INFO:tensorflow:global_step/sec: 2.17003\n",
      "INFO:tensorflow:examples/sec: 13.0202\n",
      "INFO:tensorflow:global_step/sec: 2.17589\n",
      "INFO:tensorflow:examples/sec: 13.0553\n",
      "INFO:tensorflow:global_step/sec: 2.18118\n",
      "INFO:tensorflow:examples/sec: 13.0871\n",
      "INFO:tensorflow:global_step/sec: 2.17313\n",
      "INFO:tensorflow:examples/sec: 13.0388\n",
      "INFO:tensorflow:Saving checkpoints for 18000 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.44217\n",
      "INFO:tensorflow:examples/sec: 8.65302\n",
      "INFO:tensorflow:global_step/sec: 2.21584\n",
      "INFO:tensorflow:examples/sec: 13.2951\n",
      "INFO:tensorflow:Saving checkpoints for 18200 into tmp/news_output/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.4560393.\n",
      "INFO:tensorflow:Writing example 0 of 9101\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: 36828\n",
      "INFO:tensorflow:tokens: [CLS] gear vr 用 戶 破 百 萬 ！ oculus ： 經 濟 效 益 浮 現 意 義 非 凡 moneydj 新 聞 2016 - 05 - 12 12 : 22 : 13 記 者 郭 妍 希 報 導 宏 達 電 ( 249 ##8 ) 、 社 群 網 站 巨 擘 facebook inc . ( 通 稱 臉 書 ) 執 行 長 佐 克 伯 ( mark z ##uck ##er ##berg ， 見 圖 ) 看 好 的 虛 擬 實 境 ( vr ) 科 技 有 了 大 突 破 ， 三 星 電 子 ( samsung electronic ##s co . ) 的 「 gear vr 」 用 戶 最 近 終 於 超 越 了 100 萬 人 整 數 大 關 ， 代 表 經 濟 效 益 逐 漸 浮 現 。 z ##dn ##et 、 ve ##nt ##ure ##be ##at 11 日 報 導 ， facebook 旗 下 vr 事 業 oculus 宣 布 ， gear vr 用 戶 在 今 ( 2016 ) 年 4 月 突 破 100 萬 人 ， 這 對 看 好 vr 前 景 的 企 業 來 說 意 義 非 凡 。 oculus 行 動 部 門 主 管 max co ##hen 在 本 週 一 場 記 者 會 上 接 受 cn ##et 訪 問 時 表 示 ， 100 萬 是 一 個 神 奇 數 字 ， 許 多 人 會 因 此 更 加 認 真 看 待 vr 科 技 ， 因 為 這 代 表 經 濟 效 益 浮 現 、 其 他 業 者 也 將 共 襄 盛 舉 。 目 前 vr 主 要 應 用 在 遊 戲 和 娛 樂 領 域 ， 不 過 ， 根 據 科 技 市 調 機 構 for ##res ##ter 的 最 新 報 告 ， 現 在 正 是 vr 業 者 開 始 拓 展 商 用 領 域 的 時 候 。 報 告 指 出 ， vr 以 及 擴 增 實 境 ( ar ) 、 混 合 實 境 ( mr ) 能 夠 增 加 企 業 與 顧 客 的 互 動 ， 還 能 提 升 員 工 效 率 、 協 助 訓 練 員 工 ， 並 為 客 戶 帶 來 視 覺 體 驗 。 舉 例 來 說 ， 3d 視 覺 化 技 術 商 da ##ss ##au ##lt s ##ys ##t ? me ##s 目 前 正 在 與 宏 達 電 合 作 ， 運 用 htc vive 開 發 產 品 設 計 、 製 造 與 工 程 的 應 用 程 式 。 除 了 htc vive 之 外 ， se ##ns ##ics 的 os ##vr 中 介 軟 體 、 微 軟 的 ho ##lo ##len ##s 、 ap ##x lab ##s 的 sky ##light 軟 體 套 件 以 及 mar ##x ##ent visual ##com ##mer ##ce 平 台 也 跨 入 了 商 用 vr 領 域 ， 潛 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 10231 8260 4500 2786 4788 4636 5857 8013 10480 8038 5195 4089 3126 4660 3859 4412 2692 5412 7478 1127 11911 3173 5472 8112 118 8137 118 8110 8110 131 8130 131 8124 6250 5442 6958 1970 2361 1841 2206 2131 6888 7442 113 10705 8156 114 510 4852 5408 5206 4991 2342 3086 8200 8910 119 113 6858 4935 5622 3292 114 1822 6121 7269 858 1046 843 113 8970 168 11971 8196 10039 8024 6210 1756 114 4692 1962 4638 5995 3093 2179 1862 113 8260 114 4906 2825 3300 749 1920 4960 4788 8024 676 3215 7442 2094 113 8931 9297 8118 8792 119 114 4638 519 10231 8260 520 4500 2786 3297 6818 5173 3176 6631 6632 749 8135 5857 782 3146 3149 1920 7302 8024 807 6134 5195 4089 3126 4660 6852 4041 3859 4412 511 168 10853 8418 510 12810 8511 8813 8765 8488 8111 3189 1841 2206 8024 8200 3186 678 8260 752 3511 10480 2146 2357 8024 10231 8260 4500 2786 1762 791 113 8112 114 2399 125 3299 4960 4788 8135 5857 782 8024 6857 2205 4692 1962 8260 1184 3250 4638 821 3511 889 6303 2692 5412 7478 1127 511 10480 6121 1240 6956 7271 712 5052 8621 8792 11602 1762 3315 6867 671 1842 6250 5442 3298 677 2970 1358 8274 8418 6256 1558 3229 6134 4850 8024 8135 5857 3221 671 943 4868 1936 3149 2099 8024 6258 1914 782 3298 1728 3634 3291 1217 6291 4696 4692 2521 8260 4906 2825 8024 1728 4158 6857 807 6134 5195 4089 3126 4660 3859 4412 510 1071 800 3511 5442 738 2200 1066 6198 4670 5647 511 4680 1184 8260 712 6206 2746 4500 1762 6879 2783 1469 2024 3556 7526 1818 8024 679 6882 8024 3418 3087 4906 2825 2356 6310 3582 3539 8330 9683 8457 4638 3297 3173 1841 1440 8024 4412 1762 3633 3221 8260 3511 5442 7274 1993 2868 2245 1555 4500 7526 1818 4638 3229 952 511 1841 1440 2900 1139 8024 8260 809 1350 3097 1872 2179 1862 113 8673 114 510 3921 1394 2179 1862 113 8912 114 5543 1917 1872 1217 821 3511 5645 7547 2145 4638 757 1240 8024 6917 5543 2990 1285 1519 2339 3126 4372 510 1295 1221 6246 5230 1519 2339 8024 699 4158 2145 2786 2380 889 6213 6221 7768 7710 511 5647 891 889 6303 8024 8219 6213 6221 1265 2825 6123 1555 10005 8565 9096 9238 161 9449 8165 136 8450 8118 4680 1184 3633 1762 5645 2131 6888 7442 1394 868 8024 6880 4500 8530 10167 7274 4634 4496 1501 6257 6243 510 6182 6863 5645 2339 4923 4638 2746 4500 4923 2466 511 7370 749 8530 10167 722 1912 8024 9342 8727 9034 4638 8721 10131 704 792 6727 7768 510 2544 6727 4638 10537 8897 11407 8118 510 9392 8206 11441 8118 4638 10122 9638 6727 7768 1947 816 809 1350 9118 8206 8936 10635 9479 9778 8328 2398 1378 738 6659 1057 749 1555 4500 8260 7526 1818 8024 4051 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: 40710\n",
      "INFO:tensorflow:tokens: [CLS] 匯 損 攪 局 ， 昇 貿 q3 獲 利 季 減 2 成 精 實 新 聞 2010 - 11 - 01 19 : 47 : 00 記 者 楊 喻 斐 報 導 無 鉛 錫 製 品 大 廠 昇 貿 科 技 ( 330 ##5 ) 第 三 季 受 到 匯 兌 損 失 2300 萬 元 拖 累 ， 加 上 所 得 稅 費 用 增 加 影 響 ， 單 季 稅 後 淨 利 1 . 07 億 元 ， 較 上 一 季 減 少 22 % ， 表 現 不 如 預 期 ， 累 計 前 三 季 eps ##3 . 21 元 。 昇 貿 公 佈 前 三 季 財 報 ， 合 併 營 收 為 53 . 75 億 元 ， 稅 後 淨 利 為 3 . 36 億 元 ， 以 除 權 後 股 本 10 . 54 億 計 算 ， 每 股 稅 後 盈 餘 為 3 . 21 元 。 以 昇 貿 第 三 季 單 季 來 看 ， 合 併 營 收 為 19 . 26 億 元 ， 創 下 歷 史 新 高 紀 錄 ， 季 增 率 約 1 . 2 % ； 毛 利 率 達 14 . 5 % ， 優 於 第 二 季 合 併 毛 利 率 11 . 5 % ； 營 業 淨 利 1 . 66 億 元 ， 亦 較 第 二 季 合 併 營 業 淨 利 1 . 04 億 元 成 長 約 60 % ； 稅 後 淨 利 1 . 07 億 元 ， 卻 較 上 一 季 減 少 22 % 。 昇 貿 說 明 ， 第 三 季 的 本 業 獲 利 仍 持 續 成 長 ， 不 過 業 外 因 新 台 幣 兌 美 元 大 幅 度 升 值 ， 導 致 匯 兌 損 失 金 額 2300 萬 元 ， 另 外 ， 第 二 季 因 所 得 稅 率 從 20 % 調 至 17 % 產 生 所 得 稅 回 沖 利 益 ， 不 過 第 三 季 所 得 稅 較 第 二 季 明 顯 增 加 ， 也 導 致 稅 後 淨 利 出 現 衰 退 走 勢 。 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1274 3010 3115 2229 8024 3205 6530 10982 4363 1164 2108 3938 123 2768 5125 2179 3173 5472 8166 118 8111 118 8146 8131 131 8264 131 8136 6250 5442 3501 1616 3156 1841 2206 4192 7061 7095 6182 1501 1920 2449 3205 6530 4906 2825 113 9611 8157 114 5018 676 2108 1358 1168 1274 1047 3010 1927 10000 5857 1039 2870 5168 8024 1217 677 2792 2533 4922 6527 4500 1872 1217 2512 7513 8024 1606 2108 4922 2527 3912 1164 122 119 8155 1023 1039 8024 6733 677 671 2108 3938 2208 8130 110 8024 6134 4412 679 1963 7521 3309 8024 5168 6243 1184 676 2108 9629 8152 119 8128 1039 511 3205 6530 1062 854 1184 676 2108 6512 1841 8024 1394 882 4245 3119 4158 8251 119 8273 1023 1039 8024 4922 2527 3912 1164 4158 124 119 8216 1023 1039 8024 809 7370 3609 2527 5500 3315 8108 119 8267 1023 6243 5050 8024 3680 5500 4922 2527 4659 7626 4158 124 119 8128 1039 511 809 3205 6530 5018 676 2108 1606 2108 889 4692 8024 1394 882 4245 3119 4158 8131 119 8153 1023 1039 8024 1201 678 3644 1380 3173 7770 5145 7087 8024 2108 1872 4372 5147 122 119 123 110 8039 3688 1164 4372 6888 8122 119 126 110 8024 1032 3176 5018 753 2108 1394 882 3688 1164 4372 8111 119 126 110 8039 4245 3511 3912 1164 122 119 8347 1023 1039 8024 771 6733 5018 753 2108 1394 882 4245 3511 3912 1164 122 119 8147 1023 1039 2768 7269 5147 8183 110 8039 4922 2527 3912 1164 122 119 8155 1023 1039 8024 1320 6733 677 671 2108 3938 2208 8130 110 511 3205 6530 6303 3209 8024 5018 676 2108 4638 3315 3511 4363 1164 793 2898 5265 2768 7269 8024 679 6882 3511 1912 1728 3173 1378 2395 1047 5401 1039 1920 2388 2428 1285 966 8024 2206 5636 1274 1047 3010 1927 7032 7540 10000 5857 1039 8024 1369 1912 8024 5018 753 2108 1728 2792 2533 4922 4372 2537 8113 110 6310 5635 8126 110 4496 4495 2792 2533 4922 1726 3762 1164 4660 8024 679 6882 5018 676 2108 2792 2533 4922 6733 5018 753 2108 3209 7549 1872 1217 8024 738 2206 5636 4922 2527 3912 1164 1139 4412 6139 6842 6624 1248 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: 19651\n",
      "INFO:tensorflow:tokens: [CLS] 中 信 金 併 r ##bs 大 馬 子 行 案 宣 告 破 局 moneydj 新 聞 2016 - 08 - 09 09 : 14 : 13 記 者 新 聞 中 心 報 導 中 信 金 控 ( 289 ##1 ) 昨 ( 8 ) 日 晚 間 公 告 ， 中 國 信 託 銀 行 和 台 灣 人 壽 共 同 出 資 擬 收 購 蘇 格 蘭 皇 家 銀 行 ( r ##bs ) 馬 來 西 亞 子 行 100 % 股 權 一 案 ， 因 送 件 不 及 ， 無 法 趕 在 期 限 內 的 11 月 底 前 完 成 收 購 程 序 ， 雙 方 已 合 意 宣 布 終 止 合 約 。 中 信 金 今 年 4 月 時 宣 布 ， 將 透 過 中 信 銀 和 台 壽 以 馬 來 西 亞 幣 7 . 399 億 元 ( 約 61 . 03 ##8 億 台 幣 ) ， 取 得 蘇 格 蘭 皇 家 銀 行 ( the royal bank of sc ##ot ##land ) 馬 來 西 亞 子 行 100 % 股 權 ， 中 信 將 成 為 台 灣 金 融 業 中 首 家 取 得 馬 來 西 亞 子 行 的 業 者 。 不 過 ， 該 收 購 案 昨 晚 即 宣 布 破 局 。 中 信 金 指 出 ， 此 交 易 案 原 預 定 最 晚 須 在 11 月 15 日 完 成 相 關 作 業 ， 但 因 考 量 其 相 關 作 業 文 件 不 及 準 備 ， 可 能 無 法 如 期 送 件 給 台 、 馬 主 管 機 關 ， 而 拖 累 r ##bs 撤 離 馬 國 時 程 ， 因 此 只 好 忍 痛 放 棄 。 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 704 928 7032 882 160 9071 1920 7679 2094 6121 3428 2146 1440 4788 2229 11911 3173 5472 8112 118 8142 118 8141 8141 131 8122 131 8124 6250 5442 3173 5472 704 2552 1841 2206 704 928 7032 2971 113 11520 8148 114 3219 113 129 114 3189 3241 7279 1062 1440 8024 704 1751 928 6249 7065 6121 1469 1378 4124 782 1904 1066 1398 1139 6536 3093 3119 6554 5979 3419 5984 4640 2157 7065 6121 113 160 9071 114 7679 889 6205 765 2094 6121 8135 110 5500 3609 671 3428 8024 1728 6843 816 679 1350 8024 4192 3791 6634 1762 3309 7361 1058 4638 8111 3299 2419 1184 2130 2768 3119 6554 4923 2415 8024 7427 3175 2347 1394 2692 2146 2357 5173 3632 1394 5147 511 704 928 7032 791 2399 125 3299 3229 2146 2357 8024 2200 6851 6882 704 928 7065 1469 1378 1904 809 7679 889 6205 765 2395 128 119 9612 1023 1039 113 5147 8398 119 8140 8156 1023 1378 2395 114 8024 1357 2533 5979 3419 5984 4640 2157 7065 6121 113 8174 11019 10717 8205 11515 8783 8789 114 7679 889 6205 765 2094 6121 8135 110 5500 3609 8024 704 928 2200 2768 4158 1378 4124 7032 6084 3511 704 7674 2157 1357 2533 7679 889 6205 765 2094 6121 4638 3511 5442 511 679 6882 8024 6283 3119 6554 3428 3219 3241 1315 2146 2357 4788 2229 511 704 928 7032 2900 1139 8024 3634 769 3211 3428 1333 7521 2137 3297 3241 7519 1762 8111 3299 8115 3189 2130 2768 4685 7302 868 3511 8024 852 1728 5440 7030 1071 4685 7302 868 3511 3152 816 679 1350 3976 991 8024 1377 5543 4192 3791 1963 3309 6843 816 5183 1378 510 7679 712 5052 3582 7302 8024 5445 2870 5168 160 9071 3059 7431 7679 1751 3229 4923 8024 1728 3634 1372 1962 2556 4578 3123 3468 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: 8252\n",
      "INFO:tensorflow:tokens: [CLS] 宏 達 電 推 6 吋 全 螢 幕 新 智 慧 手 機 搭 載 超 大 光 圈 雙 主 鏡 頭 moneydj 新 聞 2018 - 05 - 22 10 : 25 : 46 記 者 新 聞 中 心 報 導 宏 達 電 ( 249 ##8 ) 於 今 ( 22 ) 日 宣 布 htc des ##ire 系 列 新 成 員 htc des ##ire 12 + 在 台 上 市 ， 儲 存 容 量 搭 載 3g ##b ram + 32gb rom ， 全 台 htc 專 賣 店 、 htc 網 路 商 店 將 於 今 ( 22 ) 日 開 放 預 購 ， 6 月 1 日 起 於 中 華 電 信 、 台 灣 大 與 遠 傳 、 亞 太 電 與 台 灣 之 星 門 市 全 面 開 賣 。 宏 達 電 表 示 ， htc des ##ire 12 + 擁 有 絕 佳 性 價 比 ， 且 為 des ##ire 系 列 史 上 首 支 搭 配 雙 鏡 頭 手 機 及 最 大 尺 寸 的 6 吋 18 ： 9 全 螢 幕 。 宏 達 電 指 出 ， htc des ##ire 12 + 雙 主 鏡 頭 搭 配 超 大 ? / 2 . 2 光 圈 ， 可 捕 捉 更 多 光 線 ， 即 使 在 光 源 不 足 的 環 境 下 ， 也 能 拍 出 精 準 細 節 ， 同 時 也 能 捕 捉 多 個 焦 點 ， 散 景 特 效 則 是 套 用 清 晰 的 前 景 和 自 然 的 模 糊 背 景 ， 讓 拍 出 的 相 片 更 有 藝 術 感 ； 搭 載 具 備 「 相 位 偵 側 自 動 對 焦 pd ##af 」 ， 動 態 取 景 也 能 捕 捉 清 晰 的 細 節 。 而 自 拍 鏡 頭 的 前 置 led 閃 光 燈 與 全 新 柔 光 自 拍 燈 光 ， 無 時 無 刻 提 供 自 然 清 晰 的 自 拍 照 片 。 除 此 之 外 ， 在 htc u 系 列 上 備 受 好 評 的 智 慧 數 位 助 理 htc sense com ##pan ##ion 也 預 載 於 htc des ##ire 系 列 上 。 宏 達 電 補 充 ， htc sense com ##pan ##ion 透 過 長 時 間 瞭 解 使 用 者 的 生 活 模 式 和 行 程 ， 讓 生 活 中 的 每 一 個 行 程 更 加 便 利 ， 除 了 會 預 先 提 醒 您 近 期 的 會 議 、 活 動 或 節 日 ， 甚 至 會 在 無 行 程 安 排 的 假 日 早 晨 自 動 關 閉 鬧 鐘 ， 讓 使 用 者 有 更 充 分 的 休 息 時 間 ； 更 可 以 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2131 6888 7442 2972 127 1397 1059 6086 2391 3173 3255 2716 2797 3582 3022 6734 6631 1920 1045 1750 7427 712 7128 7531 11911 3173 5472 8271 118 8137 118 8130 8108 131 8132 131 8248 6250 5442 3173 5472 704 2552 1841 2206 2131 6888 7442 113 10705 8156 114 3176 791 113 8130 114 3189 2146 2357 8530 11081 9764 5143 1154 3173 2768 1519 8530 11081 9764 8110 116 1762 1378 677 2356 8024 1033 2100 2159 7030 3022 6734 8456 8204 9270 116 11155 8891 8024 1059 1378 8530 2201 6546 2421 510 8530 5206 6662 1555 2421 2200 3176 791 113 8130 114 3189 7274 3123 7521 6554 8024 127 3299 122 3189 6629 3176 704 5836 7442 928 510 1378 4124 1920 5645 6895 1001 510 765 1922 7442 5645 1378 4124 722 3215 7271 2356 1059 7481 7274 6546 511 2131 6888 7442 6134 4850 8024 8530 11081 9764 8110 116 3075 3300 5179 881 2595 1019 3683 8024 684 4158 11081 9764 5143 1154 1380 677 7674 3118 3022 6981 7427 7128 7531 2797 3582 1350 3297 1920 2223 2189 4638 127 1397 8123 8038 130 1059 6086 2391 511 2131 6888 7442 2900 1139 8024 8530 11081 9764 8110 116 7427 712 7128 7531 3022 6981 6631 1920 136 120 123 119 123 1045 1750 8024 1377 2936 2929 3291 1914 1045 5221 8024 1315 886 1762 1045 3975 679 6639 4638 4472 1862 678 8024 738 5543 2864 1139 5125 3976 5169 5059 8024 1398 3229 738 5543 2936 2929 1914 943 4193 7953 8024 3141 3250 4294 3126 1179 3221 1947 4500 3926 3251 4638 1184 3250 1469 5632 4197 4638 3563 5128 5520 3250 8024 6366 2864 1139 4638 4685 4275 3291 3300 5971 6123 2697 8039 3022 6734 1072 991 519 4685 855 980 979 5632 1240 2205 4193 9884 11472 520 8024 1240 2706 1357 3250 738 5543 2936 2929 3926 3251 4638 5169 5059 511 5445 5632 2864 7128 7531 4638 1184 5390 8242 7272 1045 4236 5645 1059 3173 3382 1045 5632 2864 4236 1045 8024 4192 3229 4192 1174 2990 897 5632 4197 3926 3251 4638 5632 2864 4212 4275 511 7370 3634 722 1912 8024 1762 8530 163 5143 1154 677 991 1358 1962 6268 4638 3255 2716 3149 855 1221 4415 8530 12647 8134 12297 8410 738 7521 6734 3176 8530 11081 9764 5143 1154 677 511 2131 6888 7442 6171 1041 8024 8530 12647 8134 12297 8410 6851 6882 7269 3229 7279 4747 6237 886 4500 5442 4638 4495 3833 3563 2466 1469 6121 4923 8024 6366 4495 3833 704 4638 3680 671 943 6121 4923 3291 1217 912 1164 8024 7370 749 3298 7521 1044 2990 7008 2644 6818 3309 4638 3298 6359 510 3833 1240 2772 5059 3189 8024 4493 5635 3298 1762 4192 6121 4923 2128 2961 4638 969 3189 3193 3247 5632 1240 7302 7273 7785 7132 8024 6366 886 4500 5442 3300 3291 1041 1146 4638 828 2622 3229 7279 8039 3291 1377 809 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 1 (id = 1)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: 1920\n",
      "INFO:tensorflow:tokens: [CLS] 《 偏 光 板 》 奇 美 材 研 發 主 管 晉 升 ； 明 基 材 換 董 座 精 實 新 聞 2013 - 10 - 01 05 : 43 : 27 記 者 許 曉 嘉 報 導 偏 光 板 廠 高 層 人 事 近 期 分 別 傳 出 異 動 調 整 。 其 中 ， 奇 美 材 （ 49 ##60 ） 於 9 / 30 公 告 該 公 司 原 生 產 暨 研 發 總 處 協 理 陳 宗 民 協 理 晉 升 為 副 總 經 理 ， 主 要 係 因 應 公 司 組 織 管 理 及 業 務 需 要 。 另 外 ， 友 達 光 電 （ 240 ##9 ） 集 團 旗 下 偏 光 板 廠 明 基 材 （ 82 ##15 ） 亦 於 上 周 通 過 董 事 長 職 務 異 動 案 。 原 任 明 基 材 董 事 長 李 文 德 自 2013 年 10 / 1 起 辭 去 董 事 長 職 務 ， 改 由 明 基 材 董 事 陳 建 志 接 任 董 座 。 而 明 基 材 原 執 行 長 游 克 用 亦 同 時 以 個 人 因 素 為 由 請 辭 ， 自 2013 年 10 / 1 辭 去 執 行 長 職 務 ， 改 由 明 基 材 新 任 董 事 長 陳 建 志 兼 任 執 行 長 。 陳 建 智 為 瑞 士 聯 邦 理 工 大 學 材 料 科 學 博 士 ， 曾 任 飛 利 浦 產 品 開 發 經 理 、 達 方 電 子 ( 816 ##3 ) 電 子 陶 瓷 元 件 事 業 部 副 總 經 理 ， 兼 任 台 南 廠 區 / 整 合 通 訊 元 件 事 業 部 主 管 ， 總 計 進 入 明 基 友 達 集 團 服 務 至 今 16 年 。 奇 美 材 生 產 暨 研 發 總 處 副 總 經 理 陳 宗 民 則 畢 業 於 台 大 化 工 系 、 清 華 化 工 所 ， 曾 任 奇 美 實 業 副 處 長 。 [SEP]\n",
      "INFO:tensorflow:input_ids: 101 517 974 1045 3352 518 1936 5401 3332 4777 4634 712 5052 3231 1285 8039 3209 1825 3332 2994 5869 2429 5125 2179 3173 5472 8138 118 8108 118 8146 8137 131 8250 131 8149 6250 5442 6258 3280 1649 1841 2206 974 1045 3352 2449 7770 2251 782 752 6818 3309 1146 1162 1001 1139 4530 1240 6310 3146 511 1071 704 8024 1936 5401 3332 8020 8249 8581 8021 3176 130 120 8114 1062 1440 6283 1062 1385 1333 4495 4496 3270 4777 4634 5244 5993 1295 4415 7376 2134 3696 1295 4415 3231 1285 4158 1199 5244 5195 4415 8024 712 6206 913 1728 2746 1062 1385 5175 5251 5052 4415 1350 3511 1243 7444 6206 511 1369 1912 8024 1351 6888 1045 7442 8020 8821 8160 8021 7415 1757 3186 678 974 1045 3352 2449 3209 1825 3332 8020 8460 8493 8021 771 3176 677 1453 6858 6882 5869 752 7269 5480 1243 4530 1240 3428 511 1333 818 3209 1825 3332 5869 752 7269 3330 3152 2548 5632 8138 2399 8108 120 122 6629 6798 1343 5869 752 7269 5480 1243 8024 3121 4507 3209 1825 3332 5869 752 7376 2456 2562 2970 818 5869 2429 511 5445 3209 1825 3332 1333 1822 6121 7269 3952 1046 4500 771 1398 3229 809 943 782 1728 5162 4158 4507 6313 6798 8024 5632 8138 2399 8108 120 122 6798 1343 1822 6121 7269 5480 1243 8024 3121 4507 3209 1825 3332 3173 818 5869 752 7269 7376 2456 2562 1076 818 1822 6121 7269 511 7376 2456 3255 4158 4448 1894 5474 6930 4415 2339 1920 2119 3332 3160 4906 2119 1300 1894 8024 3295 818 7606 1164 3855 4496 1501 7274 4634 5195 4415 510 6888 3175 7442 2094 113 10937 8152 114 7442 2094 7378 4487 1039 816 752 3511 6956 1199 5244 5195 4415 8024 1076 818 1378 1298 2449 1281 120 3146 1394 6858 6244 1039 816 752 3511 6956 712 5052 8024 5244 6243 6868 1057 3209 1825 1351 6888 7415 1757 3302 1243 5635 791 8121 2399 511 1936 5401 3332 4495 4496 3270 4777 4634 5244 5993 1199 5244 5195 4415 7376 2134 3696 1179 4525 3511 3176 1378 1920 1265 2339 5143 510 3926 5836 1265 2339 2792 8024 3295 818 1936 5401 2179 3511 1199 5993 7269 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 1 (id = 1)\n",
      "INFO:tensorflow:***** Running evaluation *****\n",
      "INFO:tensorflow:  Num examples = 9101 (9101 actual, 0 padding)\n",
      "INFO:tensorflow:  Batch size = 8\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 512)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 512)\n",
      "INFO:tensorflow:  name = is_real_example, shape = (?,)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 512)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (21128, 768)\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,)\n",
      "INFO:tensorflow:  name = output_weights:0, shape = (2, 768)\n",
      "INFO:tensorflow:  name = output_bias:0, shape = (2,)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-24-17:36:14\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2019-06-24 17:36:15.341582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2019-06-24 17:36:15.341835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-06-24 17:36:15.341852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 1 2 3 \n",
      "2019-06-24 17:36:15.341864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N Y Y Y \n",
      "2019-06-24 17:36:15.341873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 1:   Y N Y Y \n",
      "2019-06-24 17:36:15.341883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 2:   Y Y N Y \n",
      "2019-06-24 17:36:15.341892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 3:   Y Y Y N \n",
      "2019-06-24 17:36:15.342580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10405 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:07:00.0, compute capability: 6.1)\n",
      "2019-06-24 17:36:15.342732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10405 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1)\n",
      "2019-06-24 17:36:15.342837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10405 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:0c:00.0, compute capability: 6.1)\n",
      "2019-06-24 17:36:15.342963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10405 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:0e:00.0, compute capability: 6.1)\n",
      "INFO:tensorflow:Restoring parameters from tmp/news_output/model.ckpt-18200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-24-17:39:41\n",
      "INFO:tensorflow:Saving dict for global step 18200: eval_accuracy = 0.8613339, eval_loss = 0.4014244, global_step = 18200, loss = 0.40133312\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18200: tmp/news_output/model.ckpt-18200\n",
      "INFO:tensorflow:***** Eval results *****\n",
      "INFO:tensorflow:  eval_accuracy = 0.8613339\n",
      "INFO:tensorflow:  eval_loss = 0.4014244\n",
      "INFO:tensorflow:  global_step = 18200\n",
      "INFO:tensorflow:  loss = 0.40133312\n"
     ]
    }
   ],
   "source": [
    "!python run_classifier.py \\\n",
    "  --task_name=News\\\n",
    "  --do_train=true \\\n",
    "  --do_eval=true \\\n",
    "  --data_dir=. \\\n",
    "  --vocab_file=chinese_L-12_H-768_A-12/vocab.txt \\\n",
    "  --bert_config_file=chinese_L-12_H-768_A-12/bert_config.json \\\n",
    "  --init_checkpoint= chinese_L-12_H-768_A-12/bert_model.ckpt \\\n",
    "  --max_seq_length=512 \\\n",
    "  --output_dir=tmp/news_output \\\n",
    "  --train_batch_size=6 \\\n",
    "  --learning_rate=2e-5 \\\n",
    "  --num_train_epochs=3.0 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
